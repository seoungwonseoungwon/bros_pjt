{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7306df36-fc5a-4c7e-a301-ce102effa7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.3532 - accuracy: 0.0417 - val_loss: 2.2570 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3241 - accuracy: 0.0417 - val_loss: 2.2463 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2956 - accuracy: 0.0417 - val_loss: 2.2373 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2679 - accuracy: 0.1250 - val_loss: 2.2291 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.2413 - accuracy: 0.2083 - val_loss: 2.2222 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2157 - accuracy: 0.2083 - val_loss: 2.2160 - val_accuracy: 0.1667\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1911 - accuracy: 0.2083 - val_loss: 2.2105 - val_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1668 - accuracy: 0.3333 - val_loss: 2.2060 - val_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1434 - accuracy: 0.4583 - val_loss: 2.2011 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1208 - accuracy: 0.4583 - val_loss: 2.1954 - val_accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0986 - accuracy: 0.4583 - val_loss: 2.1897 - val_accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0766 - accuracy: 0.4583 - val_loss: 2.1843 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0546 - accuracy: 0.4583 - val_loss: 2.1794 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0329 - accuracy: 0.4583 - val_loss: 2.1761 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0121 - accuracy: 0.4583 - val_loss: 2.1733 - val_accuracy: 0.3333\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9916 - accuracy: 0.4583 - val_loss: 2.1705 - val_accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9715 - accuracy: 0.4583 - val_loss: 2.1687 - val_accuracy: 0.3333\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9518 - accuracy: 0.4583 - val_loss: 2.1684 - val_accuracy: 0.3333\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9325 - accuracy: 0.4583 - val_loss: 2.1691 - val_accuracy: 0.3333\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9130 - accuracy: 0.4583 - val_loss: 2.1712 - val_accuracy: 0.3333\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8941 - accuracy: 0.4583 - val_loss: 2.1752 - val_accuracy: 0.3333\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8756 - accuracy: 0.5000 - val_loss: 2.1800 - val_accuracy: 0.3333\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8572 - accuracy: 0.5000 - val_loss: 2.1844 - val_accuracy: 0.3333\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8388 - accuracy: 0.5000 - val_loss: 2.1893 - val_accuracy: 0.3333\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8204 - accuracy: 0.5000 - val_loss: 2.1948 - val_accuracy: 0.3333\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8020 - accuracy: 0.5000 - val_loss: 2.2010 - val_accuracy: 0.3333\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7835 - accuracy: 0.5000 - val_loss: 2.2077 - val_accuracy: 0.3333\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7650 - accuracy: 0.5000 - val_loss: 2.2150 - val_accuracy: 0.3333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7467 - accuracy: 0.5000 - val_loss: 2.2224 - val_accuracy: 0.3333\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7283 - accuracy: 0.5000 - val_loss: 2.2302 - val_accuracy: 0.3333\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7096 - accuracy: 0.5000 - val_loss: 2.2378 - val_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6906 - accuracy: 0.5417 - val_loss: 2.2459 - val_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6716 - accuracy: 0.5417 - val_loss: 2.2543 - val_accuracy: 0.1667\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6527 - accuracy: 0.5833 - val_loss: 2.2640 - val_accuracy: 0.1667\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6341 - accuracy: 0.5833 - val_loss: 2.2736 - val_accuracy: 0.1667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6155 - accuracy: 0.5833 - val_loss: 2.2834 - val_accuracy: 0.1667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5965 - accuracy: 0.5833 - val_loss: 2.2938 - val_accuracy: 0.1667\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5777 - accuracy: 0.5833 - val_loss: 2.3045 - val_accuracy: 0.1667\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5589 - accuracy: 0.5833 - val_loss: 2.3154 - val_accuracy: 0.1667\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5404 - accuracy: 0.5833 - val_loss: 2.3265 - val_accuracy: 0.1667\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5219 - accuracy: 0.5833 - val_loss: 2.3387 - val_accuracy: 0.1667\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.5036 - accuracy: 0.5833 - val_loss: 2.3518 - val_accuracy: 0.1667\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4852 - accuracy: 0.5833 - val_loss: 2.3654 - val_accuracy: 0.1667\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4669 - accuracy: 0.5833 - val_loss: 2.3799 - val_accuracy: 0.1667\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4485 - accuracy: 0.5833 - val_loss: 2.3952 - val_accuracy: 0.1667\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4304 - accuracy: 0.5833 - val_loss: 2.4113 - val_accuracy: 0.1667\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4124 - accuracy: 0.5833 - val_loss: 2.4284 - val_accuracy: 0.1667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3945 - accuracy: 0.5833 - val_loss: 2.4453 - val_accuracy: 0.1667\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3768 - accuracy: 0.5833 - val_loss: 2.4623 - val_accuracy: 0.1667\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3592 - accuracy: 0.5833 - val_loss: 2.4789 - val_accuracy: 0.1667\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3418 - accuracy: 0.5833 - val_loss: 2.4954 - val_accuracy: 0.1667\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3246 - accuracy: 0.5833 - val_loss: 2.5125 - val_accuracy: 0.1667\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3077 - accuracy: 0.5833 - val_loss: 2.5306 - val_accuracy: 0.1667\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2910 - accuracy: 0.5833 - val_loss: 2.5494 - val_accuracy: 0.1667\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2746 - accuracy: 0.5833 - val_loss: 2.5688 - val_accuracy: 0.1667\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2585 - accuracy: 0.5833 - val_loss: 2.5890 - val_accuracy: 0.1667\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2424 - accuracy: 0.5833 - val_loss: 2.6099 - val_accuracy: 0.1667\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2267 - accuracy: 0.5833 - val_loss: 2.6312 - val_accuracy: 0.1667\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2112 - accuracy: 0.5833 - val_loss: 2.6527 - val_accuracy: 0.1667\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1960 - accuracy: 0.5833 - val_loss: 2.6746 - val_accuracy: 0.1667\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1810 - accuracy: 0.5833 - val_loss: 2.6969 - val_accuracy: 0.1667\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1663 - accuracy: 0.5833 - val_loss: 2.7196 - val_accuracy: 0.1667\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1519 - accuracy: 0.5833 - val_loss: 2.7429 - val_accuracy: 0.1667\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1379 - accuracy: 0.5833 - val_loss: 2.7667 - val_accuracy: 0.1667\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1241 - accuracy: 0.5833 - val_loss: 2.7907 - val_accuracy: 0.1667\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1106 - accuracy: 0.5833 - val_loss: 2.8151 - val_accuracy: 0.1667\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0974 - accuracy: 0.5833 - val_loss: 2.8396 - val_accuracy: 0.1667\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0845 - accuracy: 0.5833 - val_loss: 2.8646 - val_accuracy: 0.1667\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0719 - accuracy: 0.5833 - val_loss: 2.8904 - val_accuracy: 0.1667\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0597 - accuracy: 0.5833 - val_loss: 2.9167 - val_accuracy: 0.1667\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0477 - accuracy: 0.5833 - val_loss: 2.9419 - val_accuracy: 0.1667\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0362 - accuracy: 0.5833 - val_loss: 2.9669 - val_accuracy: 0.1667\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0250 - accuracy: 0.5833 - val_loss: 2.9917 - val_accuracy: 0.1667\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0141 - accuracy: 0.5833 - val_loss: 3.0168 - val_accuracy: 0.1667\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0034 - accuracy: 0.5833 - val_loss: 3.0424 - val_accuracy: 0.1667\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9931 - accuracy: 0.5833 - val_loss: 3.0685 - val_accuracy: 0.1667\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9831 - accuracy: 0.5833 - val_loss: 3.0948 - val_accuracy: 0.1667\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9734 - accuracy: 0.5833 - val_loss: 3.1216 - val_accuracy: 0.1667\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9639 - accuracy: 0.5833 - val_loss: 3.1485 - val_accuracy: 0.1667\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9548 - accuracy: 0.5833 - val_loss: 3.1753 - val_accuracy: 0.1667\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9459 - accuracy: 0.5833 - val_loss: 3.2018 - val_accuracy: 0.1667\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9373 - accuracy: 0.5833 - val_loss: 3.2282 - val_accuracy: 0.1667\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9289 - accuracy: 0.5833 - val_loss: 3.2552 - val_accuracy: 0.1667\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9208 - accuracy: 0.5833 - val_loss: 3.2826 - val_accuracy: 0.1667\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9130 - accuracy: 0.5833 - val_loss: 3.3103 - val_accuracy: 0.1667\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9053 - accuracy: 0.5833 - val_loss: 3.3391 - val_accuracy: 0.1667\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8979 - accuracy: 0.5833 - val_loss: 3.3680 - val_accuracy: 0.1667\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8907 - accuracy: 0.5833 - val_loss: 3.3973 - val_accuracy: 0.1667\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8837 - accuracy: 0.5833 - val_loss: 3.4268 - val_accuracy: 0.1667\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8769 - accuracy: 0.5833 - val_loss: 3.4568 - val_accuracy: 0.1667\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8704 - accuracy: 0.5833 - val_loss: 3.4868 - val_accuracy: 0.1667\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8641 - accuracy: 0.5833 - val_loss: 3.5166 - val_accuracy: 0.1667\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8580 - accuracy: 0.5833 - val_loss: 3.5471 - val_accuracy: 0.1667\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8520 - accuracy: 0.5833 - val_loss: 3.5776 - val_accuracy: 0.1667\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8464 - accuracy: 0.5833 - val_loss: 3.6084 - val_accuracy: 0.1667\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8409 - accuracy: 0.5833 - val_loss: 3.6393 - val_accuracy: 0.1667\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8356 - accuracy: 0.5833 - val_loss: 3.6701 - val_accuracy: 0.1667\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8305 - accuracy: 0.5833 - val_loss: 3.7011 - val_accuracy: 0.1667\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8256 - accuracy: 0.5833 - val_loss: 3.7321 - val_accuracy: 0.1667\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8209 - accuracy: 0.5833 - val_loss: 3.7632 - val_accuracy: 0.1667\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7632 - accuracy: 0.1667\n",
      "검증 세트 손실: 3.7631921768188477\n",
      "검증 세트 정확도: 0.1666666716337204\n",
      "INFO:tensorflow:Assets written to: path_to_model_directory\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_model_directory\\assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 훈련 데이터를 불러옵니다.\n",
    "train_data = pd.read_csv(\"KBO_TRAIN.csv\")\n",
    "\n",
    "# 특성(X)과 타겟(y)으로 나눕니다.\n",
    "X_train, y_train = train_data.drop('GRADE', axis=1), train_data['GRADE']\n",
    "\n",
    "# Convert class labels to be in the range from 0 to 9\n",
    "y_train = y_train - 1\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 나눕니다.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-Hot Encoding을 수행하여 팀 이름을 숫자로 변환\n",
    "encoder = OneHotEncoder()\n",
    "X_combined = pd.concat([X_train, X_val])  # Combine the training and validation sets\n",
    "X_encoded = encoder.fit_transform(X_combined[['TEAM']])\n",
    "\n",
    "# 데이터 전처리를 진행합니다.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_encoded[:len(X_train)].toarray())\n",
    "X_val_scaled = scaler.transform(X_encoded[len(X_train):].toarray())\n",
    "\n",
    "# 신경망 모델의 구조를 정의합니다.\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # KBO 팀 수에 해당하는 10개의 클래스 (0부터 9)\n",
    "])\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "# 검증 세트로 모델을 평가합니다.\n",
    "val_loss, val_accuracy = model.evaluate(X_val_scaled, y_val)\n",
    "print(\"검증 세트 손실:\", val_loss)\n",
    "print(\"검증 세트 정확도:\", val_accuracy)\n",
    "\n",
    "# 훈련된 모델을 파일로 저장합니다.\n",
    "# 훈련된 모델을 파일로 저장합니다.\n",
    "# 훈련된 모델을 TensorFlow's SavedModel format으로 저장합니다.\n",
    "model.save(\"path_to_model_directory\", save_format='tf')\n",
    "model.save(\"path_to_model_directory.h5\", save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6009c21-7a54-4c53-9e5f-b4cebbca3386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team",
   "language": "python",
   "name": "team"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
