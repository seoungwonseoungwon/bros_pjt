{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae02a448-f40a-4fe1-b477-9e1ac0ce0d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Features (독립 변수)와 Labels (종속 변수) 분리\n",
    "X = data.drop(columns=['team', 'kbo_ranking'])  # 'team' 컬럼 제거\n",
    "y = data['kbo_ranking']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 나눔 (예: 학습 데이터 80%, 테스트 데이터 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# RandomForestClassifier 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 모델의 성능 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"정확도: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df3e998c-dbf0-47df-8833-21a48089e2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.125\n",
      "Available years: [20 21 22 23]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['team'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_2023)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 원본 데이터에 팀 이름 및 예측된 순위 추가\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m team_names \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mavailable_years\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkbo_ranking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_2023, pd\u001b[38;5;241m.\u001b[39mSeries(predictions, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkbo_ranking_predicted\u001b[39m\u001b[38;5;124m'\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(result_df, team_names, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkbo_ranking_predicted\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkbo_ranking\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['team'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# team 컬럼 제거\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "print(\"Available years:\", available_years)\n",
    "\n",
    "# 최종 순위 예측 결과\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "predictions = model.predict(X_2023)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "result_df = pd.concat([X_2023, pd.Series(predictions, name='kbo_ranking_predicted')], axis=1)\n",
    "result_df = pd.merge(result_df, team_names, how='left', left_on='kbo_ranking_predicted', right_on='kbo_ranking')\n",
    "result_df = result_df.drop(columns=['kbo_ranking_y'])\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "249c0603-1864-4d8d-a975-e7921d409ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.125\n",
      "최종 순위 예측 결과:\n",
      "  team  kbo_ranking_predicted\n",
      "0   LG                      1\n",
      "1   NC                      4\n",
      "2  SSG                      2\n",
      "3   두산                      3\n",
      "4  KIA                      7\n",
      "5   키움                      8\n",
      "6   KT                      7\n",
      "7   한화                      8\n",
      "8   삼성                     10\n",
      "9   롯데                      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "\n",
    "# team 컬럼 제거\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=52)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# 23년 최종 순위 예측\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "predictions = model.predict(X_2023)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "result_df = pd.DataFrame({'team': team_names['team'], 'kbo_ranking_predicted': predictions})\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01e5aa77-2178-46f9-b1fb-db4317d24aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.125\n",
      "최종 순위 예측 결과:\n",
      "  team  kbo_ranking_predicted\n",
      "0   LG                      1\n",
      "1   NC                      4\n",
      "2  SSG                      2\n",
      "3   두산                      3\n",
      "4  KIA                      7\n",
      "5   키움                      9\n",
      "6   KT                      6\n",
      "7   한화                      9\n",
      "8   삼성                     10\n",
      "9   롯데                      5\n"
     ]
    }
   ],
   "source": [
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "\n",
    "# team 컬럼 제거\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# 23년 최종 순위 예측\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "predictions = model.predict(X_2023)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "result_df = pd.DataFrame({'team': team_names['team'], 'kbo_ranking_predicted': predictions})\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638cb17-bbf6-4814-a614-cba9315e4b02",
   "metadata": {},
   "source": [
    "## minmax 스케일러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2215cf39-a621-457f-aaa0-c434c5afbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.125\n",
      "최종 순위 예측 결과:\n",
      "  team  kbo_ranking_predicted\n",
      "0   LG                      1\n",
      "1   NC                      4\n",
      "2  SSG                      2\n",
      "3   두산                      3\n",
      "4  KIA                      7\n",
      "5   키움                      9\n",
      "6   KT                      6\n",
      "7   한화                      9\n",
      "8   삼성                     10\n",
      "9   롯데                      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "\n",
    "# team 컬럼 제거\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# Feature Scaling using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# 23년 최종 순위 예측\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "X_2023_scaled = scaler.transform(X_2023)\n",
    "predictions = model.predict(X_2023_scaled)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "result_df = pd.DataFrame({'team': team_names['team'], 'kbo_ranking_predicted': predictions})\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f614e00b-271d-49c2-93ef-dc2513ac3f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.125\n",
      "최종 순위 예측 결과:\n",
      "  team  kbo_ranking_predicted\n",
      "0   LG                      1\n",
      "1   NC                      4\n",
      "2  SSG                      2\n",
      "3   두산                      3\n",
      "4  KIA                      7\n",
      "5   키움                      9\n",
      "6   KT                      6\n",
      "7   한화                      9\n",
      "8   삼성                     10\n",
      "9   롯데                      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "\n",
    "# team 컬럼 제거\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# Feature Scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# 23년 최종 순위 예측\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "X_2023_scaled = scaler.transform(X_2023)\n",
    "predictions = model.predict(X_2023_scaled)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "result_df = pd.DataFrame({'team': team_names['team'], 'kbo_ranking_predicted': predictions})\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "649aff94-e347-4d08-8edc-8f8b0651fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.0\n",
      "분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "           5       0.00      0.00      0.00       0.0\n",
      "           6       0.00      0.00      0.00       0.0\n",
      "           7       0.00      0.00      0.00       2.0\n",
      "           8       0.00      0.00      0.00       3.0\n",
      "           9       0.00      0.00      0.00       0.0\n",
      "          10       0.00      0.00      0.00       2.0\n",
      "\n",
      "    accuracy                           0.00       8.0\n",
      "   macro avg       0.00      0.00      0.00       8.0\n",
      "weighted avg       0.00      0.00      0.00       8.0\n",
      "\n",
      "최종 순위 예측 결과:\n",
      "  team  kbo_ranking_predicted\n",
      "0   LG                      1\n",
      "1   NC                      4\n",
      "2  SSG                      2\n",
      "3   두산                      3\n",
      "4  KIA                      7\n",
      "5   키움                      9\n",
      "6   KT                      6\n",
      "7   한화                      9\n",
      "8   삼성                     10\n",
      "9   롯데                      5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ml.csv 파일 로드\n",
    "file_path = \"ml.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# unique한 년도 값 확인\n",
    "available_years = df['year'].unique()\n",
    "\n",
    "# team 컬럼 제거\n",
    "team_names = df[df['year'] == available_years[-1]][['team', 'kbo_ranking']].drop_duplicates().reset_index(drop=True)\n",
    "df = df.drop(columns=['team'])\n",
    "\n",
    "# 학습 데이터 준비\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# 학습 데이터와 테스트 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 분류기 모델 생성\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 측정\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"정확도:\", accuracy)\n",
    "\n",
    "# 분류 리포트 출력\n",
    "print(\"분류 리포트:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 23년 최종 순위 예측\n",
    "X_2023 = df[df['year'] == available_years[-1]].drop(columns=['kbo_ranking'])\n",
    "predictions = model.predict(X_2023)\n",
    "\n",
    "# 원본 데이터에 팀 이름 및 예측된 순위 추가\n",
    "result_df = pd.DataFrame({'team': team_names['team'], 'kbo_ranking_predicted': predictions})\n",
    "\n",
    "print(\"최종 순위 예측 결과:\")\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f994e072-ceb5-4c66-ba1d-69c6c7da0da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'LG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m     12\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 13\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 훈련 데이터와 테스트 데이터로 분할\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:873\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    872\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 873\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\utils\\validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mC:\\playdata_lab\\team\\team\\lib\\site-packages\\pandas\\core\\generic.py:1998\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   1997\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1998\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2000\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2001\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2002\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2003\u001b[0m     ):\n\u001b[0;32m   2004\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2006\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2007\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'LG'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('ml.csv')\n",
    "\n",
    "# 특성(X)과 타겟(y) 분리\n",
    "X = df.drop(columns=['kbo_ranking'])\n",
    "y = df['kbo_ranking']\n",
    "\n",
    "# 특성들을 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터로 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18a759-6f4b-4160-8c3f-29f79a0a9928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team",
   "language": "python",
   "name": "team"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
